import streamlit as st
import os
import pandas as pd

import torch, auto_gptq
from transformers import AutoTokenizer, AutoModel, AutoModelForCausalLM
from auto_gptq.modeling import BaseGPTQForCausalLM
from torchvision import transforms
from torchvision.transforms.functional import InterpolationMode

from langchain.vectorstores.faiss import FAISS
from langchain_community.embeddings.huggingface import HuggingFaceEmbeddings


from database.database import engine
from sqlalchemy import text
from datetime import datetime

from utils import is_cuda_available, is_cuda_enough
from utils import cuda_size_24gb, cuda_size_40gb
from utils import image_to_base64, update_aigc_perm_freq


marketing_prompt = """ä½ æ˜¯ä¸€ä½ä¼˜ç§€çš„æœè£…å•†å“æ™ºèƒ½é”€å”®ä¸“å®¶ï¼Œä½ ç°åœ¨è¦æ¨é”€ä¸€ä»¶æœè£…ï¼Œæœè£…å•†å“çš„è¯¦ç»†ä¿¡æ¯å¦‚ä¸‹ï¼š
å•†å“åç§°ï¼š{product_name}
å•†å“æ ‡ç­¾ï¼š{product_tags}
å•†å“ç±»å‹ï¼š{product_gender}
é€‚åˆå­£èŠ‚ï¼š{product_season}
å•†å“ä»·æ ¼ï¼š{product_price}
è®¾è®¡é£æ ¼ï¼š{product_style}
æœè£…æè´¨ï¼š{product_material}
å•†å“æè¿°ï¼š{product_description}

è¯·æ ¹æ®å•†å“è¯¦æƒ…ä¿¡æ¯å’Œå›¾ç‰‡ä¸­çš„å•†å“ä¿¡æ¯ï¼Œç”¨ä¸­æ–‡ï¼Œå†™ä¸€æ®µ5000ä¸ªæ±‰å­—çš„ã€é€‚ç”¨äºç”µå•†çš„è¥é”€æ–‡æ¡ˆï¼ŒåŒ…å«å•†å“çš„é¢œè‰²ã€æ¬¾å¼ã€é£æ ¼ã€é€‚ç”¨åœºåˆç­‰ä¿¡æ¯ã€‚è¯·ä»…ç»™å‡ºæ–‡æ¡ˆæ­£æ–‡å†…å®¹ã€‚

----------

æ–‡æ¡ˆæ ¼å¼è¦æ±‚å¦‚ä¸‹ï¼š

ã€æ ‡é¢˜ã€‘
æ ‡é¢˜å†…å®¹

ã€å¯¼è¯­ã€‘
å¯¼è¯­å†…å®¹

ã€æ­£æ–‡ã€‘
æ­£æ–‡å†…å®¹

ã€äº§å“äº®ç‚¹ã€‘
äº§å“äº®ç‚¹å†…å®¹

ã€è´­ä¹°å‘¼åã€‘
è´­ä¹°å‘¼åå†…å®¹

ã€ç»“å°¾ã€‘
ç»“å°¾å†…å®¹

----------

æ–‡æ¡ˆè¦ç‚¹è¦æ±‚å¦‚ä¸‹ï¼š

1ã€æ ‡é¢˜ï¼šè¯·ç®€æ´æ˜äº†ï¼Œçªå‡ºäº§å“ç‰¹ç‚¹ï¼Œåˆ›é€ å¥½å¥‡å¿ƒï¼Œå¸å¼•ç”¨æˆ·ï¼Œæ¿€å‘ç”¨æˆ·çš„å…´è¶£ã€‚
2ã€å¯¼è¯­ï¼šç®€ä»‹è¥é”€æ´»åŠ¨çš„èƒŒæ™¯ï¼Œæ¿€å‘ç”¨æˆ·çš„å…´è¶£ã€‚
3ã€æ­£æ–‡ï¼šè¯·ç»“åˆå•†å“è¯¦æƒ…ä¿¡æ¯ã€å›¾ç‰‡è¯¦æƒ…ä¿¡æ¯ï¼Œè¯¦ç»†ä»‹ç»å•†å“ã€‚é€šè¿‡è®²è¿°ä¸€ä¸ªä¸äº§å“æœ‰å…³çš„æ•…äº‹ï¼Œåœ¨æƒ…æ„Ÿä¸Šä¸ç”¨æˆ·å»ºç«‹è”ç³»ã€‚
4ã€äº§å“äº®ç‚¹ï¼šçªå‡ºæœè£…çš„è´¨é‡ã€æ¬¾å¼ã€é¢æ–™ã€èˆ’é€‚åº¦ã€è®¾è®¡ç‹¬ç‰¹æ€§ç­‰ä¼˜åŠ¿ã€‚
5ã€è´­ä¹°å‘¼åï¼šåˆ—å‡ºä¼˜æƒ ä¿¡æ¯ï¼Œæ¿€æ´»ç”¨æˆ·çš„è´­ä¹°æ¬²æœ›ï¼Œä¿ƒä½¿ç”¨æˆ·ä¸‹å•ã€‚
6ã€ç»“å°¾ï¼šçªå‡ºå¯ä»¥ä¸ºç”¨æˆ·æä¾›è´´å¿ƒçš„æœåŠ¡ã€‚

----------

æ–‡æ¡ˆæ ·ä¾‹ï¼š

ã€æ ‡é¢˜ã€‘
æ–°å“ä¸Šå¸‚-ä½ çš„è¡£æŸœè¿˜ç¼ºè¿™ä»¶ï¼

ã€å¯¼è¯­ã€‘
äº²çˆ±çš„æ—¶å°šè¾¾äººä»¬ï¼š
æ‚¨æ˜¯å¦åŒå€¦äº†æ¯å¤©æ‰“å¼€è¡£æŸœå´æ‰¾ä¸åˆ°å¿ƒä»ªçš„æœè£…ï¼Ÿæ‚¨æ˜¯å¦æ¸´æœ›åœ¨è¿™ä¸ª{product_season}å­£èŠ‚é‡Œï¼Œè®©è‡ªå·±æˆä¸ºç„¦ç‚¹ï¼Œå¼•é¢†æ½®æµï¼Ÿé‚£ä¹ˆã€‚æ‚¨ç»å¯¹ä¸èƒ½é”™è¿‡æˆ‘ä»¬çš„è¿™æ¬¾è¡£æœã€‚

ã€æ­£æ–‡ã€‘
ä¸€ä½å¹´è½»å¥³å­©èº«ç€ä¸€è¢­é²œè‰³çš„çº¢è‰²æ——è¢ï¼Œä¼˜é›…åœ°ç«™åœ¨é—¨å»Šå‰ã€‚å¥¹çš„çœ¼ç¥ä¸­æµéœ²å‡ºè‡ªä¿¡å’Œä¼˜é›…ï¼Œè®©è¿™è¢­çº¢è‰²çš„æ——è¢æ›´åŠ è€€çœ¼å¤ºç›®ã€‚
è¿™æ¬¾æ——è¢é‡‡ç”¨äº†ä¼ ç»Ÿçš„æ–œè¥Ÿè®¾è®¡ï¼Œé¢†å£å’Œè¢–å£å¤„ç²¾è‡´çš„ç»£èŠ±å›¾æ¡ˆç‚¹ç¼€å…¶ä¸­ï¼Œå‡¸æ˜¾äº†æ‰‹å·¥åŒ äººç²¾æ¹›çš„æŠ€è‰ºå’Œç²¾æ¹›çš„è®¾è®¡ã€‚è¿™æ¬¾æ——è¢é€‰ç”¨äº†ä¼˜è´¨ä¸ç»¸æè´¨ï¼Œæ‰‹æ„Ÿç»†è…»æŸ”è½¯ï¼Œç©¿ç€èˆ’é€‚å¤§æ–¹ï¼Œå°½æ˜¾ä¸œæ–¹å¤å…¸çš„ä¼˜é›…æ°”è´¨ã€‚
è¿™æ ·çš„çº¢è‰²æ——è¢ï¼Œæ— è®ºæ˜¯æ­é…è¥¿å¼æ™šç¤¼è£™è¿˜æ˜¯ä¸­å¼æ——è¢ï¼Œéƒ½æ˜¯ä¸€æ¬¾éå¸¸ç™¾æ­ä¸”æ—¶å°šçš„æœè£…ã€‚å®ƒä¸ä»…èƒ½å½°æ˜¾å‡ºç‹¬ç‰¹çš„ä¸ªæ€§ï¼Œè¿˜èƒ½å‡¸æ˜¾å‡ºå¥³æ€§çš„ä¼˜ç¾èº«å§¿å’Œç‹¬ç‰¹çš„æ°”è´¨ã€‚
è¿™æ¬¾çº¢è‰²æ——è¢ï¼Œæ— è®ºæ˜¯ä½œä¸ºç¤¼æœã€å®´ä¼šæœè£…ï¼Œè¿˜æ˜¯ä½œä¸ºæ—¶å°šçš„æœè£…ï¼Œéƒ½èƒ½ä¸ºæ‚¨çš„ç©¿æ­å¢æ·»ä¸€ä»½ä¼˜é›…ä¸ç‹¬ç‰¹ã€‚

ã€äº§å“äº®ç‚¹ã€‘
è¿™æ¬¾äº§å“çš„äº®ç‚¹åŒ…æ‹¬ï¼š{product_advantage}ã€‚
å¦å¤–ï¼Œå®ƒè¿˜æœ‰ä»¥ä¸‹ä¸€äº›äº®ç‚¹ï¼š
æ¬¾å¼æ–°é¢–ï¼šæˆ‘ä»¬çš„æœè£…é‡‡ç”¨{product_style}é£æ ¼è®¾è®¡ï¼Œç´§è·Ÿå…¨çƒæ—¶å°šè¶‹åŠ¿ï¼Œä¸ºæ‚¨å¸¦æ¥æ—¶å°šç•Œæœ€å‰æ²¿çš„è®¾è®¡ã€‚
æè´¨ä¼˜è‰¯ï¼šæˆ‘ä»¬çš„æœè£…ç²¾é€‰ä¼˜è´¨é¢æ–™{product_material}ï¼Œèˆ’é€‚äº²è‚¤ï¼Œè®©æ‚¨ç©¿å‡ºå¥åº·ç¾ä¸½ã€‚
ä»·æ ¼å®æƒ ï¼šæˆ‘ä»¬çš„æœè£…ä»·æ ¼ä¸º{product_price}ï¼Œåœ¨ä¿è¯é«˜å“è´¨çš„åŒæ—¶è¿˜æ‹¥æœ‰è¾ƒä½çš„ä»·æ ¼ï¼Œæˆ‘ä»¬æ‰¿è¯ºæä¾›æœ€å…·æ€§ä»·æ¯”çš„é€‰æ‹©ã€‚

ã€è´­ä¹°å‘¼åã€‘
ç°åœ¨ä¸‹å•ï¼Œäº«å—ä¸“å±ä¼˜æƒ ï¼ä¸ä»…å¦‚æ­¤ï¼Œæ‚¨è¿˜å¯ä»¥è·å¾—ç¥ç§˜çš„å°ç¤¼ç‰©å“¦ï¼å¿«æ¥æŠ¢è´­å§ï¼Œè®©è¿™ä¸ªå­£èŠ‚çš„ä½ ä¸ä¼—ä¸åŒï¼

ã€ç»“å°¾ã€‘
æœ‰ä»»ä½•ç–‘é—®æˆ–è€…éœ€è¦å¸®åŠ©ï¼Œè¯·éšæ—¶è”ç³»æˆ‘ä»¬ã€‚æˆ‘ä»¬çš„å®¢æœå›¢é˜Ÿ24å°æ—¶åœ¨çº¿ï¼Œéšæ—¶å‡†å¤‡ä¸ºæ‚¨æä¾›æœ€è´´å¿ƒçš„æœåŠ¡ã€‚

"""

marketing_prompt2 = """ä½ æ˜¯ä¸€ä½ä¼˜ç§€çš„æœè£…æ™ºèƒ½é”€å”®ä¸“å®¶ï¼Œä½ ç°åœ¨è¦æ¨é”€ä¸€ä»¶æœè£…ï¼Œæœè£…çš„è¯¦ç»†ä¿¡æ¯å¦‚ä¸‹ï¼š
å•†å“åç§°ï¼š{product_name}
å•†å“æ ‡ç­¾ï¼š{product_tags}
å•†å“ç±»å‹ï¼š{product_gender}
é€‚åˆå­£èŠ‚ï¼š{product_season}
å•†å“ä»·æ ¼ï¼š{product_price}
è®¾è®¡é£æ ¼ï¼š{product_style}
æœè£…æè´¨ï¼š{product_material}
å•†å“æè¿°ï¼š{product_description}

é¦–å…ˆï¼Œè¯·ä½ å‘æŒ¥æƒ³è±¡åŠ›ï¼Œç”¨ä¸€ä¸ªå°æ•…äº‹è®²è¿°å›¾ç‰‡ä¸­çš„ä¿¡æ¯ã€‚
å…¶æ¬¡ï¼Œè¯·ä½ æ ¹æ®æä¾›çš„å•†å“ä¿¡æ¯ç»“åˆå›¾ç‰‡ä¸­çš„å†…å®¹ï¼Œç²¾ç¡®æå–å•†å“çš„äº®ç‚¹ä»·å€¼ï¼Œæ”¾å¤§äº®ç‚¹ä»¥æ¿€å‘ç”¨æˆ·çš„è´­ä¹°æ¬²ï¼Œç”¨500å­—æ–‡æ¡ˆè¯¦ç»†æè¿°ä¸€ä¸‹è¿™ä»¶æœè£…ã€‚
æœ€åï¼Œè¯·ä½ ç‰¢è®°ï¼Œæ‰€æœ‰å†…å®¹è¯·ä½¿ç”¨ä¸­æ–‡å›ç­”ï¼å†…å®¹å¿…é¡»åŸºäºå•†å“ä¿¡æ¯æ’°å†™ï¼Œç¦æ­¢æé€ å†…å®¹ï¼
"""

class InternLMXComposer2QForCausalLM(BaseGPTQForCausalLM):
    layers_block_name = "model.layers"
    outside_layer_modules = [
        'vit', 'vision_proj', 'model.tok_embeddings', 'model.norm', 'output', 
    ]
    inside_layer_modules = [
        ["attention.wqkv.linear"],
        ["attention.wo.linear"],
        ["feed_forward.w1.linear", "feed_forward.w3.linear"],
        ["feed_forward.w2.linear"],
    ]


def load_internlm_xcomposer2_vl(**kwargs):
    if "xcomposer2_vl_model" not in st.session_state.keys():
        model_id_or_path = "models/internlm/internlm-xcomposer2-vl-7b"
        st.session_state["xcomposer2_vl_tokenizer"] = AutoTokenizer.from_pretrained(model_id_or_path, trust_remote_code=True)
        st.session_state["xcomposer2_vl_model"] = AutoModelForCausalLM.from_pretrained(model_id_or_path, device_map='cuda', trust_remote_code=True).half().eval()
        st.session_state["xcomposer2_vl_model"].tokenizer = st.session_state["xcomposer2_vl_tokenizer"]
    return st.session_state["xcomposer2_vl_tokenizer"], st.session_state["xcomposer2_vl_model"]


def load_internlm_xcomposer2_vl_4bit(**kwargs):
    # model_id_or_path="models/internlm/internlm-xcomposer2-7b-4bit"
    if "xcomposer2_vl_model" not in st.session_state.keys():
        auto_gptq.modeling._base.SUPPORTED_MODELS = ["internlm"]
        torch.set_grad_enabled(False)
        model_id_or_path="models/internlm/internlm-xcomposer2-vl-7b-4bit"

        tokenizer_path = model_id_or_path

        st.session_state["xcomposer2_vl_model"] = InternLMXComposer2QForCausalLM.from_quantized(
            model_id_or_path,
            device_map="auto",
            trust_remote_code=True,
            offload_buffers=True,
            **kwargs
        ).eval()

        st.session_state["xcomposer2_vl_tokenizer"] = AutoTokenizer.from_pretrained(
            tokenizer_path,
            trust_remote_code=True,
        )

        if is_cuda_available():
            st.session_state["xcomposer2_vl_model"] = st.session_state["xcomposer2_vl_model"].cuda()

    return st.session_state["xcomposer2_vl_tokenizer"], st.session_state["xcomposer2_vl_model"]


def image_chat_answer(image_pil):
    tokenizer, model = load_internlm_xcomposer2_vl() if is_cuda_enough(40950) else load_internlm_xcomposer2_vl_4bit()
    
    img_size = 500
    vis_processor = transforms.Compose([
            transforms.Resize((img_size, img_size),
                              interpolation=InterpolationMode.BICUBIC),
            transforms.ToTensor(),
            transforms.Normalize((0.48145466, 0.4578275, 0.40821073),
                                 (0.26862954, 0.26130258, 0.27577711)),
        ])
    
    image = vis_processor(image_pil).unsqueeze(0).half()

    if is_cuda_available():
        image = image.cuda()

    response, _ = model.chat(tokenizer, 
                            query="<ImageHere>", 
                            image=image, 
                            history=[(marketing_prompt.format(
                                product_name = st.session_state.input_product_name,
                                product_tags = st.session_state.input_product_tags,
                                product_gender = st.session_state.input_product_gender,
                                product_season = st.session_state.input_product_season,
                                product_price = st.session_state.input_product_price,
                                product_style = st.session_state.input_product_style,
                                product_material = st.session_state.input_product_material,
                                product_advantage = st.session_state.input_product_advantage,
                                product_description = st.session_state.input_product_description
                            ),"")], 
                            do_sample=True)
    return response


@st.cache_resource
def load_huggingface_embedding():
    embedding = HuggingFaceEmbeddings(model_name="models/GanymedeNil/text2vec-large-chinese")
    return embedding


def product_vector_index(persist_directory="products/product_index"):
    embedding = load_huggingface_embedding()
    if not os.path.exists(persist_directory):
        index = FAISS.from_texts([""], embedding)
    else:
        index = FAISS.load_local(persist_directory, embedding, allow_dangerous_deserialization=True)
    return index


def select_product(ids):
    with engine.connect() as conn:
        df = pd.read_sql(f"""
            select id as å•†å“ç¼–å·, name as å•†å“åç§°, title as å•†å“æ ‡é¢˜, tags as å•†å“æ ‡ç­¾,
                   gender as å•†å“ç±»å‹, season as é€‚åˆå­£èŠ‚, price as å•†å“ä»·æ ¼,
                   style as è®¾è®¡é£æ ¼, material as æœè£…æè´¨, advantage as æœè£…äº®ç‚¹,
                   marketing as è¥é”€æ–‡æ¡ˆ, description as å•†å“æè¿°,
                   image as å•†å“ä¸»å›¾, video as å•†å“è§†é¢‘
              from ai_labs_product_info
             where id in ({ids})
            """, conn)
        return df


def save_product_ratings(product_id, rating, comment):
    try:
        with engine.connect() as conn:
            date_time = datetime.now()
            sql = text(f'''
            insert into ai_labs_product_ratings(user_id, product_id, rating, comment, date_time)
            values(:user_id, :product_id, :rating, :comment, :date_time)
            ''')
            conn.execute(sql, [{
                'user_id': st.session_state.userid,
                'product_id': product_id,
                'rating': rating,
                'comment': comment,
                'date_time': date_time
            }])
            conn.commit()

            st.toast("è¯„ä»·æˆåŠŸï¼", icon="âœŒï¸")

    except Exception as e:
        st.exception(e)


def display_products(ids):
    products = select_product(ids)
    products["å•†å“ä¸»å›¾"]=products["å•†å“ä¸»å›¾"].apply(lambda x: "data:image/png;base64," + image_to_base64(x))

    for _, row in products.iterrows():
        with st.expander(row.iloc[2]):
            cols = st.columns(3)
            with cols[0]:
                tabs = st.tabs(["å•†å“ä¸»å›¾", "å•†å“è§†é¢‘"])
                with tabs[0]:
                    if row.iloc[12]:
                        st.image(row.iloc[12])
                with tabs[1]:
                    if row.iloc[10]:
                        st.video(row.iloc[13])
            with cols[1]:
                st.write("å•†å“åç§°ï¼š" + row.iloc[1])
                st.write("å•†å“æ ‡ç­¾ï¼š" + row.iloc[3])
                st.write("å•†å“ç±»å‹ï¼š" + row.iloc[4])
                st.write("é€‚åˆå­£èŠ‚ï¼š" + row.iloc[5])
                st.write("å•†å“ä»·æ ¼ï¼š" + str(row.iloc[6]))
                st.write("è®¾è®¡é£æ ¼ï¼š" + row.iloc[7])
                st.write("æœè£…æè´¨ï¼š" + row.iloc[8])
                st.write("æœè£…äº®ç‚¹ï¼š" + row.iloc[9])
            with cols[2]:
                st.markdown(row.iloc[11])
            st.markdown("-------")
            st.markdown(str(row.iloc[10]))
            st.markdown("-------")
            cols = st.columns([0.2,0.2,0.2,0.2,0.2])
            with cols[0]:
                if st.button("ğŸ‘šåœ¨çº¿è¯•ç©¿",  key=f"try_on_{row.iloc[0]}"):
                    st.session_state.tryon_id = row.iloc[0]
                    st.switch_page("pages/61ğŸ‘šåœ¨çº¿è¯•ç©¿.py")
            with cols[1]:
                if st.button("ğŸ™‹ğŸ»å•†å“å’¨è¯¢", key=f"ask_product_{row.iloc[0]}"):
                    st.session_state.tryon_id = row.iloc[0]
                    st.switch_page("pages/42ğŸ™‹ğŸ»å•†å“å’¨è¯¢.py")
            with cols[2]:
                if st.button("ğŸ’°ç«‹å³è´­ä¹°", key=f"buy_product_{row.iloc[0]}"):
                    update_aigc_perm_freq(int(row.iloc[6] * 10))
                    st.toast("è´­ä¹°æˆåŠŸï¼Œæ„Ÿè°¢æ‚¨çš„æ”¯æŒï¼", icon="ğŸ’°")
            with cols[3]:
                if st.button("ğŸ›’åŠ è´­ç‰©è½¦", key=f"favorite_product_{row.iloc[0]}"):
                    st.toast("åŠ è´­æˆåŠŸï¼Œæ„Ÿè°¢æ‚¨çš„æ”¯æŒï¼", icon="ğŸ›’")
            with cols[4]:
                with st.popover("ğŸ“æˆ‘è¦è¯„ä»·"):
                    with st.form(f"comment_product_{row.iloc[0]}_form"):
                        rating = st.number_input("è¯„åˆ†", key=f"product_rating_{row.iloc[0]}", min_value=1, max_value=5)
                        comment = st.text_area(label="è¯„è®º", key=f"product_comment_{row.iloc[0]}")
                        if st.form_submit_button("æäº¤", type="primary", use_container_width=True):
                            save_product_ratings(row.iloc[0], rating, comment)
